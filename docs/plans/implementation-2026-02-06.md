# cs-cli Comprehensive Improvement Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** å…¨é¢æ”¹è¿› cs-cli å·¥å…·ï¼ŒåŒ…æ‹¬åŸå­æ“ä½œã€è¿›ç¨‹éš”ç¦»ã€è¯­ä¹‰éªŒè¯ã€æµ‹è¯•è¦†ç›–ã€init å‘½ä»¤ã€é”™è¯¯ä¿¡æ¯æ”¹è¿›ã€äº¤äº’æ¢å¤ã€æ’¤é”€åŠŸèƒ½ã€Shell è¡¥å…¨ã€é…ç½®é¢„è§ˆå’Œå®¡è®¡æ—¥å¿—ã€‚

**Architecture:** åˆ†é˜¶æ®µå®æ–½ï¼Œæ¯ä¸ªé˜¶æ®µç‹¬ç«‹å¯æµ‹è¯•ã€‚æ–°å¢åŸå­æ“ä½œæ¨¡å—å’Œè¿›ç¨‹éš”ç¦»æ¨¡å—ç¡®ä¿å¹¶å‘å®‰å…¨ï¼Œè¯­ä¹‰éªŒè¯æ¨¡å—ç¡®ä¿é…ç½®æœ‰æ•ˆæ€§ï¼Œæµ‹è¯•è¦†ç›–æ‰€æœ‰æ–°å¢åŠŸèƒ½ã€‚

**Tech Stack:** Node.js >=18, vitest, @inquirer/prompts, chalk, commander, smol-toml

---

## Phase 1: åŸºç¡€è®¾æ–½ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰

### Task 1.1: Create atomic operation module

**Files:**
- Create: `src/core/atomic.js`
- Test: `tests/unit/atomic.test.js`

**Step 1: Write the failing test**

Create `tests/unit/atomic.test.js`:

```javascript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import { atomicReplace, atomicSwitch } from '../../src/core/atomic.js';

describe('atomic operations', () => {
  let tmpDir;

  beforeEach(() => {
    tmpDir = fs.mkdtempSync(path.join(os.tmpdir(), 'cs-cli-test-'));
  });

  afterEach(() => {
    if (fs.existsSync(tmpDir)) {
      fs.rmSync(tmpDir, { recursive: true, force: true });
    }
  });

  it('should replace file atomically', () => {
    const source = path.join(tmpDir, 'source.txt');
    const target = path.join(tmpDir, 'target.txt');

    fs.writeFileSync(source, 'new content');
    fs.writeFileSync(target, 'old content');

    atomicReplace(source, target);

    expect(fs.readFileSync(target, 'utf-8')).toBe('new content');
    expect(fs.existsSync(source)).toBe(false);
  });

  it('should handle non-existent target', () => {
    const source = path.join(tmpDir, 'source.txt');
    const target = path.join(tmpDir, 'target.txt');

    fs.writeFileSync(source, 'content');

    atomicReplace(source, target);

    expect(fs.readFileSync(target, 'utf-8')).toBe('content');
  });

  it('should perform atomic switch with temp file cleanup', () => {
    const source = path.join(tmpDir, 'source.txt');
    const target = path.join(tmpDir, 'target.txt');

    fs.writeFileSync(source, 'content');

    atomicSwitch(source, target);

    expect(fs.readFileSync(target, 'utf-8')).toBe('content');
    expect(fs.existsSync(source)).toBe(true); // source still exists
    expect(fs.existsSync(`${target}.tmp`)).toBe(false); // temp file cleaned
  });

  it('should clean up temp file on failure', () => {
    const source = path.join(tmpDir, 'source.txt');
    const target = path.join(tmpDir, 'nonexistent', 'target.txt');

    fs.writeFileSync(source, 'content');

    expect(() => atomicSwitch(source, target)).toThrow();
    // Check no temp files left
    const files = fs.readdirSync(tmpDir);
    expect(files.filter(f => f.startsWith('target.txt.tmp'))).toHaveLength(0);
  });
});
```

**Step 2: Run test to verify it fails**

Run: `npm test tests/unit/atomic.test.js`
Expected: FAIL with "Cannot find package '../../src/core/atomic.js'"

**Step 3: Write minimal implementation**

Create `src/core/atomic.js`:

```javascript
import fs from 'node:fs';

/**
 * å¹³å°ç›¸å…³çš„åŸå­æ›¿æ¢
 * Windows: å…ˆåˆ é™¤ç›®æ ‡æ–‡ä»¶ï¼Œç„¶åé‡å‘½å
 * Unix: rename() ç³»ç»Ÿè°ƒç”¨ï¼ˆåŸå­ï¼‰
 * @param {string} sourcePath - æºæ–‡ä»¶è·¯å¾„
 * @param {string} targetPath - ç›®æ ‡æ–‡ä»¶è·¯å¾„
 */
export function atomicReplace(sourcePath, targetPath) {
  if (process.platform === 'win32') {
    // Windows: å…ˆåˆ é™¤ç›®æ ‡æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œç„¶åé‡å‘½å
    if (fs.existsSync(targetPath)) {
      fs.unlinkSync(targetPath);
    }
    fs.renameSync(sourcePath, targetPath);
  } else {
    // Unix: rename() ç³»ç»Ÿè°ƒç”¨æ˜¯åŸå­çš„
    fs.renameSync(sourcePath, targetPath);
  }
}

/**
 * å®‰å…¨çš„åŸå­åˆ‡æ¢æµç¨‹
 * 1. å¤åˆ¶æºæ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
 * 2. åŸå­æ€§æ›¿æ¢ç›®æ ‡æ–‡ä»¶
 * 3. å¤±è´¥æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
 * @param {string} sourcePath - æºæ–‡ä»¶è·¯å¾„
 * @param {string} targetPath - ç›®æ ‡æ–‡ä»¶è·¯å¾„
 */
export function atomicSwitch(sourcePath, targetPath) {
  const tempPath = `${targetPath}.tmp.${Date.now()}`;

  // å¤åˆ¶åˆ°ä¸´æ—¶æ–‡ä»¶
  fs.copyFileSync(sourcePath, tempPath);

  try {
    // åŸå­æ›¿æ¢
    atomicReplace(tempPath, targetPath);
  } catch (error) {
    // å¤±è´¥æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if (fs.existsSync(tempPath)) {
      fs.unlinkSync(tempPath);
    }
    throw error;
  }
}
```

**Step 4: Run test to verify it passes**

Run: `npm test tests/unit/atomic.test.js`
Expected: PASS (4 tests)

**Step 5: Commit**

```bash
git add tests/unit/atomic.test.js src/core/atomic.js
git commit -m "feat: add atomic operation module"
```

---

### Task 1.2: Create process isolation module

**Files:**
- Create: `src/core/isolation.js`
- Test: `tests/unit/isolation.test.js`

**Step 1: Write the failing test**

Create `tests/unit/isolation.test.js`:

```javascript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import { getSessionDir, isolatedOperation, cleanupSession } from '../../src/core/isolation.js';

describe('process isolation', () => {
  afterEach(() => {
    cleanupSession();
  });

  it('should create and return session directory', () => {
    const sessionDir = getSessionDir();

    expect(sessionDir).toBeTruthy();
    expect(fs.existsSync(sessionDir)).toBe(true);
    expect(sessionDir).toContain('cs-cli-session-');
  });

  it('should return same session directory on multiple calls', () => {
    const dir1 = getSessionDir();
    const dir2 = getSessionDir();

    expect(dir1).toBe(dir2);
  });

  it('should create service-specific work directory', () => {
    const workDir = isolatedOperation('claude', (dir) => {
      expect(fs.existsSync(dir)).toBe(true);
      expect(dir).toContain('claude');
      return dir;
    });

    expect(workDir).toContain('claude');
  });

  it('should execute operation in isolated directory', () => {
    const testFile = isolatedOperation('test', (dir) => {
      const filePath = path.join(dir, 'test.txt');
      fs.writeFileSync(filePath, 'test content');
      return filePath;
    });

    expect(fs.existsSync(testFile)).toBe(true);
    expect(fs.readFileSync(testFile, 'utf-8')).toBe('test content');
  });

  it('should clean up session directory', () => {
    const sessionDir = getSessionDir();
    expect(fs.existsSync(sessionDir)).toBe(true);

    cleanupSession();

    expect(fs.existsSync(sessionDir)).toBe(false);
  });
});
```

**Step 2: Run test to verify it fails**

Run: `npm test tests/unit/isolation.test.js`
Expected: FAIL with "Cannot find package '../../src/core/isolation.js'"

**Step 3: Write minimal implementation**

Create `src/core/isolation.js`:

```javascript
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import crypto from 'node:crypto';

// ä¼šè¯ IDï¼ˆè¿›ç¨‹çº§å”¯ä¸€æ ‡è¯†ï¼‰
const SESSION_ID = crypto.randomBytes(8).toString('hex');
let SESSION_DIR = null;

/**
 * è·å–å½“å‰ä¼šè¯çš„å·¥ä½œç›®å½•
 * æ¯ä¸ªè¿›ç¨‹æœ‰ç‹¬ç«‹çš„ä¸´æ—¶ç›®å½•
 * @returns {string} ä¼šè¯ç›®å½•è·¯å¾„
 */
export function getSessionDir() {
  if (!SESSION_DIR) {
    SESSION_DIR = path.join(os.tmpdir(), `cs-cli-session-${SESSION_ID}`);
  }

  if (!fs.existsSync(SESSION_DIR)) {
    fs.mkdirSync(SESSION_DIR, { recursive: true });
  }

  return SESSION_DIR;
}

/**
 * åœ¨ä¼šè¯ç›®å½•ä¸­å®‰å…¨æ“ä½œé…ç½®
 * æ“ä½œå®ŒæˆååŸå­æ€§åœ°åŒæ­¥åˆ°ç›®æ ‡ä½ç½®
 * @param {string} service - æœåŠ¡æ ‡è¯†ï¼ˆå¦‚ 'claude', 'gemini'ï¼‰
 * @param {function} operation - åœ¨å·¥ä½œç›®å½•æ‰§è¡Œçš„æ“ä½œ
 * @returns {*} æ“ä½œçš„è¿”å›å€¼
 */
export function isolatedOperation(service, operation) {
  const sessionDir = getSessionDir();
  const workDir = path.join(sessionDir, service);

  if (!fs.existsSync(workDir)) {
    fs.mkdirSync(workDir, { recursive: true });
  }

  // åœ¨å·¥ä½œç›®å½•æ‰§è¡Œæ“ä½œ
  return operation(workDir);
}

/**
 * æ¸…ç†ä¼šè¯ç›®å½•ï¼ˆè¿›ç¨‹é€€å‡ºæ—¶è°ƒç”¨ï¼‰
 */
export function cleanupSession() {
  if (SESSION_DIR && fs.existsSync(SESSION_DIR)) {
    try {
      fs.rmSync(SESSION_DIR, { recursive: true, force: true });
      SESSION_DIR = null;
    } catch (error) {
      // é™é»˜å¤±è´¥ï¼Œé¿å…å½±å“ä¸»æµç¨‹
      console.warn(`Warning: Failed to cleanup session directory: ${error.message}`);
    }
  }
}
```

**Step 4: Run test to verify it passes**

Run: `npm test tests/unit/isolation.test.js`
Expected: PASS (5 tests)

**Step 5: Commit**

```bash
git add tests/unit/isolation.test.js src/core/isolation.js
git commit -m "feat: add process isolation module"
```

---

### Task 1.3: Create semantic validation module

**Files:**
- Create: `src/core/semantic-validator.js`
- Test: `tests/unit/semantic-validator.test.js`

**Step 1: Write the failing test**

Create `tests/unit/semantic-validator.test.js`:

```javascript
import { describe, it, expect } from 'vitest';
import {
  validateClaudeSemantic,
  validateGeminiSemantic,
  validateCodexSemantic,
  validateSemantic
} from '../../src/core/semantic-validator.js';

describe('semantic validation', () => {
  describe('Claude config', () => {
    it('should validate config with api_key', () => {
      const result = validateClaudeSemantic({
        api_key: 'sk-ant-test',
        model: 'claude-sonnet-4'
      });
      expect(result.valid).toBe(true);
      expect(result.errors).toHaveLength(0);
    });

    it('should validate config with providers', () => {
      const result = validateClaudeSemantic({
        providers: [{ name: 'openai', api_key: 'sk-test' }]
      });
      expect(result.valid).toBe(true);
    });

    it('should reject config without api_key or providers', () => {
      const result = validateClaudeSemantic({
        model: 'claude-sonnet-4'
      });
      expect(result.valid).toBe(false);
      expect(result.errors).toContain('Missing required field: api_key or providers');
    });

    it('should reject invalid model type', () => {
      const result = validateClaudeSemantic({
        api_key: 'sk-ant-test',
        model: 123
      });
      expect(result.valid).toBe(false);
      expect(result.errors).toContain('Field "model" must be a string');
    });
  });

  describe('Gemini config', () => {
    it('should validate config with GEMINI_API_KEY', () => {
      const result = validateGeminiSemantic({
        GEMINI_API_KEY: 'AIza-test'
      });
      expect(result.valid).toBe(true);
    });

    it('should validate config with API_KEY', () => {
      const result = validateGeminiSemantic({
        API_KEY: 'AIza-test'
      });
      expect(result.valid).toBe(true);
    });

    it('should reject config without API key', () => {
      const result = validateGeminiSemantic({
        MODEL: 'gemini-pro'
      });
      expect(result.valid).toBe(false);
      expect(result.errors).toContain('Missing required field: GEMINI_API_KEY or API_KEY');
    });
  });

  describe('Codex config', () => {
    it('should validate config with env_key', () => {
      const result = validateCodexSemantic({
        env_key: 'sk-test',
        base_url: 'https://api.openai.com/v1'
      });
      expect(result.valid).toBe(true);
    });

    it('should validate config with api_key', () => {
      const result = validateCodexSemantic({
        api_key: 'sk-test'
      });
      expect(result.valid).toBe(true);
    });

    it('should reject config without env_key or api_key', () => {
      const result = validateCodexSemantic({
        base_url: 'https://api.openai.com/v1'
      });
      expect(result.valid).toBe(false);
      expect(result.errors).toContain('Missing required field: env_key or api_key');
    });
  });

  describe('validateSemantic unified function', () => {
    it('should delegate to correct validator for claude', () => {
      const result = validateSemantic('claude', { api_key: 'test' });
      expect(result.valid).toBe(true);
    });

    it('should delegate to correct validator for gemini', () => {
      const result = validateSemantic('gemini', { GEMINI_API_KEY: 'test' });
      expect(result.valid).toBe(true);
    });

    it('should delegate to correct validator for codex', () => {
      const result = validateSemantic('codex', { env_key: 'test' });
      expect(result.valid).toBe(true);
    });

    it('should return valid for unknown service', () => {
      const result = validateSemantic('unknown', {});
      expect(result.valid).toBe(true);
    });
  });
});
```

**Step 2: Run test to verify it fails**

Run: `npm test tests/unit/semantic-validator.test.js`
Expected: FAIL with "Cannot find package '../../src/core/semantic-validator.js'"

**Step 3: Write minimal implementation**

Create `src/core/semantic-validator.js`:

```javascript
/**
 * Claude é…ç½®çš„è¯­ä¹‰éªŒè¯
 * @param {object} data - è§£æåçš„ JSON æ•°æ®
 * @returns {{valid: boolean, errors: Array<string>, warnings: Array<string>}}
 */
export function validateClaudeSemantic(data) {
  const errors = [];
  const warnings = [];

  // å¿…éœ€å­—æ®µï¼šapi_key æˆ– providers é…ç½®
  if (!data.api_key && !data.providers?.length) {
    errors.push('Missing required field: api_key or providers');
  }

  // å¯é€‰å­—æ®µéªŒè¯
  if (data.model !== undefined && typeof data.model !== 'string') {
    errors.push('Field "model" must be a string');
  }

  return {
    valid: errors.length === 0,
    errors,
    warnings
  };
}

/**
 * Gemini (.env) é…ç½®çš„è¯­ä¹‰éªŒè¯
 * @param {object} data - è§£æåçš„ ENV æ•°æ®
 * @returns {{valid: boolean, errors: Array<string>, warnings: Array<string>}}
 */
export function validateGeminiSemantic(data) {
  const errors = [];

  // æ£€æŸ¥å¿…éœ€çš„ API å¯†é’¥
  if (!data.GEMINI_API_KEY && !data.API_KEY) {
    errors.push('Missing required field: GEMINI_API_KEY or API_KEY');
  }

  return {
    valid: errors.length === 0,
    errors,
    warnings: []
  };
}

/**
 * Codex (TOML) é…ç½®çš„è¯­ä¹‰éªŒè¯
 * @param {object} data - è§£æåçš„ TOML æ•°æ®
 * @returns {{valid: boolean, errors: Array<string>, warnings: Array<string>}}
 */
export function validateCodexSemantic(data) {
  const errors = [];

  // æ£€æŸ¥ env_key æˆ– api_key
  if (!data.env_key && !data.api_key) {
    errors.push('Missing required field: env_key or api_key');
  }

  return {
    valid: errors.length === 0,
    errors,
    warnings: []
  };
}

/**
 * ç»Ÿä¸€çš„è¯­ä¹‰éªŒè¯å…¥å£
 * @param {string} service - æœåŠ¡æ ‡è¯†
 * @param {object} data - é…ç½®æ•°æ®
 * @returns {{valid: boolean, errors: Array<string>, warnings: Array<string>}}
 */
export function validateSemantic(service, data) {
  const validators = {
    claude: validateClaudeSemantic,
    gemini: validateGeminiSemantic,
    codex: validateCodexSemantic
  };

  const validator = validators[service];
  if (!validator) {
    // æœªçŸ¥æœåŠ¡è·³è¿‡éªŒè¯
    return { valid: true, errors: [], warnings: [] };
  }

  return validator(data);
}
```

**Step 4: Run test to verify it passes**

Run: `npm test tests/unit/semantic-validator.test.js`
Expected: PASS (13 tests)

**Step 5: Commit**

```bash
git add tests/unit/semantic-validator.test.js src/core/semantic-validator.js
git commit -m "feat: add semantic validation module"
```

---

### Task 1.4: Refactor switcher.js to use atomic and isolation modules

**Files:**
- Modify: `src/core/switcher.js:1-143`
- Test: `tests/integration/switch-flow.test.js`

**Step 1: Write the failing test**

Create `tests/integration/switch-flow.test.js`:

```javascript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import { switchConfig } from '../../src/core/switcher.js';

describe('switch flow integration', () => {
  let testDir;
  let originalEnv;

  beforeEach(() => {
    testDir = fs.mkdtempSync(path.join(os.tmpdir(), 'cs-cli-switch-'));
    originalEnv = process.env.CLAUDE_CONFIG_DIR;
    process.env.CLAUDE_CONFIG_DIR = testDir;

    // åˆ›å»ºæµ‹è¯•é…ç½®æ–‡ä»¶
    fs.mkdirSync(testDir, { recursive: true });
    fs.writeFileSync(
      path.join(testDir, 'settings.json'),
      JSON.stringify({ api_key: 'sk-default', model: 'default' })
    );
    fs.writeFileSync(
      path.join(testDir, 'settings.json.openai'),
      JSON.stringify({ api_key: 'sk-openai', model: 'gpt-4' })
    );
    fs.writeFileSync(
      path.join(testDir, 'settings.json.local'),
      JSON.stringify({ api_key: 'sk-local', model: 'local' })
    );
  });

  afterEach(() => {
    process.env.CLAUDE_CONFIG_DIR = originalEnv;
    if (fs.existsSync(testDir)) {
      fs.rmSync(testDir, { recursive: true, force: true });
    }
  });

  it('should switch configuration successfully', () => {
    const result = switchConfig('claude', 'openai');

    expect(result.success).toBe(true);
    expect(result.variant).toBe('openai');

    const currentContent = fs.readFileSync(path.join(testDir, 'settings.json'), 'utf-8');
    const currentData = JSON.parse(currentContent);
    expect(currentData.api_key).toBe('sk-openai');
  });

  it('should create backup before switching', () => {
    const result = switchConfig('claude', 'openai');

    expect(result.success).toBe(true);
    expect(result.backup).toBeTruthy();

    // æ£€æŸ¥å¤‡ä»½ç›®å½•
    const backupDir = path.join(testDir, '.cs-backups');
    expect(fs.existsSync(backupDir)).toBe(true);
  });

  it('should support dry-run mode', () => {
    const result = switchConfig('claude', 'openai', { dryRun: true });

    expect(result.success).toBe(true);
    expect(result.dryRun).toBe(true);

    // é…ç½®ä¸åº”æ”¹å˜
    const currentContent = fs.readFileSync(path.join(testDir, 'settings.json'), 'utf-8');
    const currentData = JSON.parse(currentContent);
    expect(currentData.api_key).toBe('sk-default');
  });

  it('should handle non-existent variant', () => {
    const result = switchConfig('claude', 'nonexistent');

    expect(result.success).toBe(false);
    expect(result.error).toContain('not found');
  });

  it('should validate JSON format before switching', () => {
    // åˆ›å»ºæ— æ•ˆçš„ JSON æ–‡ä»¶
    fs.writeFileSync(
      path.join(testDir, 'settings.json.invalid'),
      '{ invalid json }'
    );

    const result = switchConfig('claude', 'invalid');

    expect(result.success).toBe(false);
    expect(result.error).toContain('Invalid format');
  });
});
```

**Step 2: Run test to verify current state**

Run: `npm test tests/integration/switch-flow.test.js`
Expected: PASS (existing implementation should work, but we're adding isolation)

**Step 3: Refactor switcher.js**

Modify `src/core/switcher.js`:

```javascript
import fs from 'node:fs';
import path from 'node:path';
import { getAdapter } from './registry.js';
import { fileHash } from '../utils/hash.js';
import { createBackup as createBackupForService } from './backup.js';
import { atomicSwitch } from './atomic.js';
import { isolatedOperation, cleanupSession } from './isolation.js';

/**
 * åˆ‡æ¢åˆ°æŒ‡å®šé…ç½®
 * @param {string} service - æœåŠ¡æ ‡è¯† (claude/gemini/codex)ï¼Œé»˜è®¤ä¸º claude
 * @param {string} variant - é…ç½®å˜ä½“åç§°
 * @param {object} options - { dryRun: boolean, noBackup: boolean }
 * @returns {object}
 */
export function switchConfig(service, variant, options = {}) {
  // å…¼å®¹æ—§æ¥å£ï¼šå¦‚æœç¬¬äºŒä¸ªå‚æ•°æ˜¯å¯¹è±¡ï¼Œè¯´æ˜ service æœªä¼ é€’
  if (typeof variant === 'object') {
    options = variant;
    variant = service;
    service = 'claude';
  }

  const { dryRun = false, noBackup = false } = options;

  const adapter = getAdapter(service);
  if (!adapter) {
    return {
      success: false,
      error: `Unknown coding tool: "${service}"`,
      suggestions: listAvailableServices()
    };
  }

  const sourcePath = adapter.getVariantPath(variant);
  const targetPath = adapter.getTargetPath();

  // 1. æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
  if (!fs.existsSync(sourcePath)) {
    return {
      success: false,
      error: `Configuration variant "${variant}" not found`,
      suggestions: listAvailableVariants(adapter)
    };
  }

  // 2. æ ¼å¼æ ¡éªŒ
  const validation = adapter.validate(sourcePath);
  if (!validation.valid) {
    const errorMsg = validation.errors
      ? validation.errors.join('; ')
      : validation.error || 'Unknown validation error';

    return {
      success: false,
      error: `Invalid format in ${adapter.getBaseName()}.${variant}: ${errorMsg}`
    };
  }

  // Dry-run æ¨¡å¼åªéªŒè¯ï¼Œä¸æ‰§è¡Œ
  if (dryRun) {
    return {
      success: true,
      dryRun: true,
      service,
      message: `Would switch ${service} to "${variant}"`,
      source: sourcePath,
      target: targetPath
    };
  }

  // 3. å¤‡ä»½å½“å‰é…ç½®
  let backupResult = null;
  if (fs.existsSync(targetPath) && !noBackup) {
    backupResult = createBackupForService(service);
    if (!backupResult.success) {
      return {
        success: false,
        error: `Failed to create backup: ${backupResult.error}`
      };
    }
  }

  try {
    // 4. ä½¿ç”¨è¿›ç¨‹éš”ç¦» + åŸå­æ“ä½œè¿›è¡Œåˆ‡æ¢
    isolatedOperation(service, (workDir) => {
      const tempPath = path.join(workDir, adapter.getBaseName());

      // åœ¨ä¼šè¯ç›®å½•å‡†å¤‡æ–‡ä»¶
      fs.copyFileSync(sourcePath, tempPath);

      // åŸå­æ›¿æ¢åˆ°ç›®æ ‡ä½ç½®
      atomicSwitch(tempPath, targetPath);
    });

    // 5. è®¡ç®—å“ˆå¸Œå¹¶æ›´æ–°çŠ¶æ€
    const hash = fileHash(targetPath);
    adapter.writeState(variant, hash);

    // 6. Codex ç‰¹æ®Šå¤„ç†ï¼šæ›´æ–° auth.json
    if (service === 'codex' && typeof adapter.updateAuthJson === 'function') {
      const authResult = adapter.updateAuthJson(targetPath);
      if (!authResult.success) {
        // auth.json æ›´æ–°å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œä½†è®°å½•è­¦å‘Š
        console.warn(`Warning: Failed to update auth.json: ${authResult.error}`);
      }
    }

    return {
      success: true,
      service,
      variant,
      backup: backupResult?.timestamp || null,
      message: `Switched ${service} to "${variant}"`
    };
  } catch (error) {
    return {
      success: false,
      error: `Failed to switch: ${error.message}`
    };
  } finally {
    // ç¡®ä¿æ¸…ç†ä¼šè¯
    cleanupSession();
  }
}

/**
 * é¢„è§ˆåˆ‡æ¢å·®å¼‚
 * @param {string} service - æœåŠ¡æ ‡è¯†
 * @param {string} variant
 * @returns {object}
 */
export function previewSwitch(service, variant) {
  return switchConfig(service, variant, { dryRun: true });
}

/**
 * åˆ—å‡ºå¯ç”¨çš„æœåŠ¡
 * @returns {Array<string>}
 */
function listAvailableServices() {
  const { listServices } = require('./registry.js');
  return listServices().map(s => s.id);
}

/**
 * åˆ—å‡ºæŒ‡å®šæœåŠ¡çš„å¯ç”¨é…ç½®å˜ä½“
 * @param {ServiceAdapter} adapter
 * @returns {Array<string>}
 */
function listAvailableVariants(adapter) {
  return adapter.scanVariants().map(v => v.name);
}
```

**Step 4: Run test to verify it passes**

Run: `npm test tests/integration/switch-flow.test.js`
Expected: PASS (6 tests)

**Step 5: Commit**

```bash
git add src/core/switcher.js tests/integration/switch-flow.test.js
git commit -m "refactor: use atomic and isolation modules in switcher"
```

---

## Phase 2: åŠŸèƒ½å¢å¼ºï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰

### Task 2.1: Create init command

**Files:**
- Create: `src/commands/init.js`
- Test: `tests/e2e/init-workflow.test.js`

**Step 1: Write the failing test**

Create `tests/e2e/init-workflow.test.js`:

```javascript
import { describe, it, expect, afterEach } from 'vitest';
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import { initCommand } from '../../src/commands/init.js';

describe('init command e2e', () => {
  let testDir;
  let originalEnv;

  beforeEach(() => {
    testDir = fs.mkdtempSync(path.join(os.tmpdir(), 'cs-cli-init-'));
    originalEnv = process.env.CLAUDE_CONFIG_DIR;
  });

  afterEach(() => {
    process.env.CLAUDE_CONFIG_DIR = originalEnv;
    if (fs.existsSync(testDir)) {
      fs.rmSync(testDir, { recursive: true, force: true });
    }
  });

  it('should create config directory when it does not exist', async () => {
    process.env.CLAUDE_CONFIG_DIR = testDir;

    // Mock inquirer to auto-confirm
    const result = await initCommand('claude');

    expect(fs.existsSync(testDir)).toBe(true);
  });

  it('should create example config file', async () => {
    process.env.CLAUDE_CONFIG_DIR = testDir;

    await initCommand('claude');

    const configPath = path.join(testDir, 'settings.json');
    expect(fs.existsSync(configPath)).toBe(true);

    const content = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
    expect(content.api_key).toBeTruthy();
  });
});
```

**Step 2: Run test to verify it fails**

Run: `npm test tests/e2e/init-workflow.test.js`
Expected: FAIL with "Cannot find package '../../src/commands/init.js'"

**Step 3: Write minimal implementation**

Create `src/commands/init.js`:

```javascript
import inquirer from '@inquirer/prompts';
import chalk from 'chalk';
import fs from 'node:fs';
import path from 'node:path';
import { getAdapter } from '../core/registry.js';

/**
 * åˆå§‹åŒ–æŒ‡å®šæœåŠ¡çš„é…ç½®
 * @param {string} service - æœåŠ¡æ ‡è¯†
 */
export async function initCommand(service = 'claude') {
  console.log(chalk.cyan(`\nğŸš€ Initializing ${service} configuration...\n`));

  const adapter = getAdapter(service);
  if (!adapter) {
    console.log(chalk.red(`Unknown service: ${service}`));
    return { success: false, error: `Unknown service: ${service}` };
  }

  const configDir = adapter.getConfigDir();

  // 1. æ£€æŸ¥å¹¶åˆ›å»ºé…ç½®ç›®å½•
  if (!fs.existsSync(configDir)) {
    const { shouldCreate } = await inquirer.prompt({
      type: 'confirm',
      name: 'shouldCreate',
      message: `Create config directory at ${configDir}?`,
      default: true
    });

    if (shouldCreate) {
      fs.mkdirSync(configDir, { recursive: true });
      console.log(chalk.green('âœ“ Directory created'));
    } else {
      console.log(chalk.gray('Init cancelled'));
      return { success: false, cancelled: true };
    }
  }

  // 2. æ£€æŸ¥ç°æœ‰é…ç½®
  const targetPath = adapter.getTargetPath();
  if (fs.existsSync(targetPath)) {
    console.log(chalk.yellow(`\nâš  Existing config found at ${targetPath}`));

    const { action } = await inquirer.prompt({
      type: 'list',
      name: 'action',
      message: 'What would you like to do?',
      choices: [
        { name: 'Create a new variant from existing config', value: 'variant' },
        { name: 'Overwrite existing config (not recommended)', value: 'overwrite' },
        { name: 'Cancel', value: 'cancel' }
      ]
    });

    if (action === 'cancel') {
      return { success: false, cancelled: true };
    }
    if (action === 'variant') {
      return await createVariant(adapter, targetPath);
    }
  }

  // 3. åˆ›å»ºç¤ºä¾‹é…ç½®
  return await createExampleConfig(adapter, targetPath);
}

/**
 * ä»ç°æœ‰é…ç½®åˆ›å»ºå˜ä½“
 */
async function createVariant(adapter, targetPath) {
  const { variantName } = await inquirer.prompt({
    type: 'input',
    name: 'variantName',
    message: 'Enter variant name (e.g., openai, local):',
    validate: input => input.trim().length > 0 || 'Name cannot be empty'
  });

  const variantPath = adapter.getVariantPath(variantName);
  fs.copyFileSync(targetPath, variantPath);

  console.log(chalk.green(`âœ“ Created variant: ${variantPath}`));
  return { success: true, variant: variantName };
}

/**
 * åˆ›å»ºç¤ºä¾‹é…ç½®
 */
async function createExampleConfig(adapter, targetPath) {
  const examples = getServiceExamples();
  const service = adapter.id;
  const example = examples[service];

  if (!example) {
    console.log(chalk.yellow(`No example available for ${service}`));
    return { success: false, error: 'No example available' };
  }

  console.log(chalk.cyan('\nğŸ“ Creating example configuration:\n'));
  console.log(chalk.gray(example.comment));

  const { confirm } = await inquirer.prompt({
    type: 'confirm',
    name: 'confirm',
    message: 'Create this example config?',
    default: true
  });

  if (confirm) {
    fs.writeFileSync(targetPath, example.content);
    console.log(chalk.green(`âœ“ Created: ${targetPath}`));
    console.log(chalk.yellow('\nâš  Please edit the config with your actual credentials'));
    return { success: true };
  }

  return { success: false, cancelled: true };
}

/**
 * è·å–æœåŠ¡ç¤ºä¾‹é…ç½®
 */
function getServiceExamples() {
  return {
    claude: {
      comment: '# Example Claude settings.json',
      content: JSON.stringify({
        api_key: 'sk-ant-your-key-here',
        model: 'claude-sonnet-4-20250514',
        max_tokens: 200000
      }, null, 2)
    },
    gemini: {
      comment: '# Example Gemini .env',
      content: 'GEMINI_API_KEY=your-key-here\n'
    },
    codex: {
      comment: '# Example Codex config.toml',
      content: 'env_key = "sk-your-key-here"\n'
    }
  };
}
```

**Step 4: Run test to verify it passes**

Run: `npm test tests/e2e/init-workflow.test.js`
Expected: PASS (2 tests, may need mocking for inquirer)

**Step 5: Commit**

```bash
git add src/commands/init.js tests/e2e/init-workflow.test.js
git commit -m "feat: add init command"
```

---

### Task 2.2: Create error formatter module

**Files:**
- Create: `src/utils/error-formatter.js`
- Test: `tests/unit/error-formatter.test.js`

**Step 1: Write the failing test**

Create `tests/unit/error-formatter.test.js`:

```javascript
import { describe, it, expect } from 'vitest';
import {
  formatVariantNotFoundError,
  formatValidationError
} from '../../src/utils/error-formatter.js';

describe('error formatter', () => {
  it('should format variant not found error', () => {
    const adapter = {
      getConfigDir: () => '/test/.claude',
      getVariantPath: (v) => `/test/.claude/settings.json.${v}`,
      scanVariants: () => [{ name: 'default' }, { name: 'local' }]
    };

    const result = formatVariantNotFoundError('claude', 'openai', adapter);

    expect(result.title).toBeTruthy();
    expect(result.details).toBeDefined();
    expect(result.suggestions).toBeDefined();
  });

  it('should format validation error', () => {
    const result = formatValidationError('/test/settings.json', {
      message: 'Unexpected token'
    });

    expect(result.title).toBeTruthy();
    expect(result.details).toBeDefined();
    expect(result.suggestions).toBeDefined();
  });
});
```

**Step 2: Run test to verify it fails**

Run: `npm test tests/unit/error-formatter.test.js`
Expected: FAIL with "Cannot find package '../../src/utils/error-formatter.js'"

**Step 3: Write minimal implementation**

Create `src/utils/error-formatter.js`:

```javascript
import chalk from 'chalk';

/**
 * æ ¼å¼åŒ–é…ç½®æœªæ‰¾åˆ°é”™è¯¯
 * @param {string} service - æœåŠ¡æ ‡è¯†
 * @param {string} variant - å˜ä½“åç§°
 * @param {object} adapter - æœåŠ¡é€‚é…å™¨
 * @returns {{title: string, details: Array<string>, suggestions: Array<string>}}
 */
export function formatVariantNotFoundError(service, variant, adapter) {
  const targetDir = adapter.getConfigDir();
  const expectedPath = adapter.getVariantPath(variant);
  const availableVariants = adapter.scanVariants();

  return {
    title: chalk.red('Configuration variant not found'),
    details: [
      chalk.gray(`Service: ${service}`),
      chalk.gray(`Variant: ${variant}`),
      chalk.gray(`Expected path: ${expectedPath}`),
      '',
      chalk.yellow('Available variants:'),
      ...availableVariants.map(v => chalk.gray(`  - ${v.name}`))
    ],
    suggestions: [
      `Check the file exists at: ${expectedPath}`,
      `Ensure the directory exists: ${targetDir}`,
      `Available variants: ${availableVariants.map(v => v.name).join(', ')}`
    ]
  };
}

/**
 * æ ¼å¼åŒ–éªŒè¯é”™è¯¯ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
 * @param {string} filePath - æ–‡ä»¶è·¯å¾„
 * @param {Error} error - é”™è¯¯å¯¹è±¡
 * @returns {{title: string, details: Array<string>, suggestions: Array<string>}}
 */
export function formatValidationError(filePath, error) {
  return {
    title: chalk.red('Configuration validation failed'),
    details: [
      chalk.gray(`File: ${filePath}`),
      '',
      chalk.yellow('Error:'),
      chalk.gray(`  ${error.message}`)
    ],
    suggestions: [
      'Check the file syntax',
      'Ensure all required fields are present',
      `Run: cs-cli validate ${filePath}`
    ]
  };
}

/**
 * è¾“å‡ºæ ¼å¼åŒ–çš„é”™è¯¯ä¿¡æ¯
 * @param {object} formattedError - æ ¼å¼åŒ–åçš„é”™è¯¯å¯¹è±¡
 */
export function printError(formattedError) {
  console.log(`\n${formattedError.title}`);
  if (formattedError.details) {
    console.log(formattedError.details.join('\n'));
  }
  if (formattedError.suggestions) {
    console.log(chalk.yellow('\nSuggestions:'));
    console.log(formattedError.suggestions.map(s => `  ${s}`).join('\n'));
  }
  console.log();
}
```

**Step 4: Run test to verify it passes**

Run: `npm test tests/unit/error-formatter.test.js`
Expected: PASS (2 tests)

**Step 5: Commit**

```bash
git add src/utils/error-formatter.js tests/unit/error-formatter.test.js
git commit -m "feat: add error formatter module"
```

---

### Task 2.3: Create history and undo module

**Files:**
- Create: `src/core/history.js`
- Create: `src/commands/undo.js`
- Test: `tests/unit/history.test.js`

**Step 1: Write the failing test**

Create `tests/unit/history.test.js`:

```javascript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import { undoSwitch, getHistory } from '../../src/core/history.js';
import { createBackup } from '../../src/core/backup.js';

describe('history and undo', () => {
  let testDir;
  let originalEnv;

  beforeEach(() => {
    testDir = fs.mkdtempSync(path.join(os.tmpdir(), 'cs-cli-history-'));
    originalEnv = process.env.CLAUDE_CONFIG_DIR;
    process.env.CLAUDE_CONFIG_DIR = testDir;

    // åˆ›å»ºé…ç½®
    fs.mkdirSync(path.join(testDir, '.cs-backups'), { recursive: true });
  });

  afterEach(() => {
    process.env.CLAUDE_CONFIG_DIR = originalEnv;
    if (fs.existsSync(testDir)) {
      fs.rmSync(testDir, { recursive: true, force: true });
    }
  });

  it('should return error when no backups exist', () => {
    const result = undoSwitch('claude');

    expect(result.success).toBe(false);
    expect(result.error).toContain('No previous backup');
  });

  it('should return error when only one backup exists', () => {
    createBackup('claude');

    const result = undoSwitch('claude');

    expect(result.success).toBe(false);
    expect(result.error).toContain('No previous backup');
  });

  it('should get history from backups', () => {
    createBackup('claude');

    const history = getHistory('claude', 10);

    expect(Array.isArray(history)).toBe(true);
    expect(history.length).toBeGreaterThan(0);
  });
});
```

**Step 2: Run test to verify it fails**

Run: `npm test tests/unit/history.test.js`
Expected: FAIL with "Cannot find package '../../src/core/history.js'"

**Step 3: Write minimal implementation**

Create `src/core/history.js`:

```javascript
import { listBackups, restoreBackup } from './backup.js';
import fs from 'node:fs';

/**
 * æ’¤é”€æœ€åä¸€æ¬¡åˆ‡æ¢
 * é€šè¿‡æ¢å¤ä¸Šä¸€ä¸ªå¤‡ä»½æ¥å®ç°
 * @param {string} service - æœåŠ¡æ ‡è¯†
 * @returns {{success: boolean, error?: string, restoredFrom?: string}}
 */
export function undoSwitch(service = 'claude') {
  const backups = listBackups(service);

  if (backups.length < 2) {
    return {
      success: false,
      error: 'No previous backup found. Cannot undo.'
    };
  }

  // å€’æ•°ç¬¬äºŒä¸ªå¤‡ä»½æ˜¯åˆ‡æ¢å‰çš„çŠ¶æ€
  const previousBackup = backups[1];

  return restoreBackup(service, previousBackup.timestamp);
}

/**
 * è·å–åˆ‡æ¢å†å²
 * åŸºäºå¤‡ä»½æ—¶é—´æˆ³æ¨æ–­
 * @param {string} service - æœåŠ¡æ ‡è¯†
 * @param {number} limit - è¿”å›æ¡æ•°é™åˆ¶
 * @returns {Array<{timestamp: string, variant: string, isCurrent: boolean}>}
 */
export function getHistory(service = 'claude', limit = 10) {
  const backups = listBackups(service);
  const statePath = getStatePath(service);

  let currentVariant = 'unknown';
  if (fs.existsSync(statePath)) {
    try {
      const state = JSON.parse(fs.readFileSync(statePath, 'utf-8'));
      currentVariant = state.current || 'unknown';
    } catch {
      // çŠ¶æ€æ–‡ä»¶æŸåï¼Œä½¿ç”¨é»˜è®¤å€¼
    }
  }

  return backups.slice(0, limit).map((backup, index) => ({
    timestamp: backup.timestamp,
    variant: index === 0 ? currentVariant : `backup-${backup.timestamp.slice(-6)}`,
    isCurrent: index === 0
  }));
}

/**
 * è·å–çŠ¶æ€æ–‡ä»¶è·¯å¾„
 * @param {string} service - æœåŠ¡æ ‡è¯†
 * @returns {string}
 */
function getStatePath(service) {
  const { getAdapter } = require('./registry.js');
  const adapter = getAdapter(service);
  if (!adapter) {
    return '';
  }
  return path.join(adapter.getConfigDir(), '.cs-state.json');
}
```

**Step 4: Run test to verify it passes**

Run: `npm test tests/unit/history.test.js`
Expected: PASS (4 tests)

**Step 5: Create undo command**

Create `src/commands/undo.js`:

```javascript
import { undoSwitch } from '../core/history.js';
import { logAudit } from '../utils/logger.js';
import chalk from 'chalk';

/**
 * æ’¤é”€æœ€åä¸€æ¬¡åˆ‡æ¢
 * @param {object} options - { service: string }
 */
export function undoCommand(options = {}) {
  const { service = 'claude' } = options;

  const result = undoSwitch(service);

  logAudit({
    action: 'undo',
    service,
    success: result.success
  });

  if (result.success) {
    console.log(chalk.green(`âœ“ Undid last ${service} switch`));
    if (result.restoredFrom) {
      console.log(chalk.gray(`Restored from: ${result.restoredFrom}`));
    }
  } else {
    console.log(chalk.red(`âœ— Failed: ${result.error}`));
  }

  return result;
}
```

**Step 6: Commit**

```bash
git add src/core/history.js src/commands/undo.js tests/unit/history.test.js
git commit -m "feat: add history and undo functionality"
```

---

### Task 2.4: Update restore command for interactive selection

**Files:**
- Modify: `src/commands/restore.js`

**Step 1: Modify restore.js to support interactive selection**

Replace `src/commands/restore.js` content with:

```javascript
import inquirer from '@inquirer/prompts';
import chalk from 'chalk';
import { listBackups, restoreBackup } from '../core/backup.js';

/**
 * æ¢å¤é…ç½®å¤‡ä»½
 * @param {string} service - æœåŠ¡æ ‡è¯†
 * @param {string} timestamp - å¤‡ä»½æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼Œäº¤äº’å¼é€‰æ‹©ï¼‰
 */
export async function restoreCommand(service, timestamp) {
  // å¦‚æœæä¾›äº†æ—¶é—´æˆ³ï¼Œç›´æ¥æ¢å¤
  if (timestamp) {
    return restoreBackup(service, timestamp);
  }

  // äº¤äº’å¼é€‰æ‹©
  const backups = listBackups(service);

  if (backups.length === 0) {
    console.log(chalk.yellow('No backups found'));
    return { success: false, error: 'No backups found' };
  }

  const { selected } = await inquirer.prompt({
    type: 'list',
    name: 'selected',
    message: `Select a ${service} backup to restore:`,
    choices: backups.map(b => ({
      name: formatBackupChoice(b),
      value: b.timestamp
    }))
  });

  const result = restoreBackup(service, selected);

  if (result.success) {
    console.log(chalk.green(`âœ“ Restored from ${selected}`));
  } else {
    console.log(chalk.red(`âœ— ${result.error}`));
  }

  return result;
}

/**
 * æ ¼å¼åŒ–å¤‡ä»½é€‰é¡¹æ˜¾ç¤º
 * @param {{timestamp: string, name: string, path: string}} backup
 * @returns {string}
 */
function formatBackupChoice(backup) {
  const ts = backup.timestamp;
  const date = new Date(
    ts.slice(0, 4),
    parseInt(ts.slice(4, 6)) - 1,
    ts.slice(6, 8),
    ts.slice(8, 10),
    ts.slice(10, 12),
    ts.slice(12, 14)
  );

  const relative = getRelativeTime(date);
  return `${backup.timestamp} (${relative})`;
}

/**
 * è·å–ç›¸å¯¹æ—¶é—´æè¿°
 * @param {Date} date
 * @returns {string}
 */
function getRelativeTime(date) {
  const now = new Date();
  const diff = now - date;
  const minutes = Math.floor(diff / 60000);
  const hours = Math.floor(diff / 3600000);
  const days = Math.floor(diff / 86400000);

  if (minutes < 1) return 'just now';
  if (minutes < 60) return `${minutes}m ago`;
  if (hours < 24) return `${hours}h ago`;
  return `${days}d ago`;
}
```

**Step 2: Run existing tests to verify**

Run: `npm test tests/backup.test.js`
Expected: PASS (if exists, otherwise skip)

**Step 3: Commit**

```bash
git add src/commands/restore.js
git commit -m "feat: add interactive restore selection"
```

---

## Phase 3: ä½“éªŒä¼˜åŒ–ï¼ˆä½ä¼˜å…ˆçº§ï¼‰

### Task 3.1: Create audit logger module

**Files:**
- Create: `src/utils/logger.js`
- Create: `src/commands/audit.js`
- Test: `tests/unit/logger.test.js`

**Step 1: Write the failing test**

Create `tests/unit/logger.test.js`:

```javascript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import {
  logAudit,
  readAuditLog,
  logSwitch,
  logBackup,
  logRestore
} from '../../src/utils/logger.js';

describe('audit logger', () => {
  let testDir;
  let originalHome;

  beforeEach(() => {
    testDir = fs.mkdtempSync(path.join(os.tmpdir(), 'cs-cli-audit-'));
    originalHome = process.env.HOME;
    // Mock HOME directory
    process.env.HOME = testDir;
  });

  afterEach(() => {
    process.env.HOME = originalHome;
    if (fs.existsSync(testDir)) {
      fs.rmSync(testDir, { recursive: true, force: true });
    }
  });

  it('should log audit events', () => {
    logAudit({ action: 'test', data: 'value' });

    const logs = readAuditLog();
    expect(logs.length).toBe(1);
    expect(logs[0].event.action).toBe('test');
  });

  it('should log switch events', () => {
    logSwitch('claude', 'openai', true);

    const logs = readAuditLog();
    expect(logs.length).toBe(1);
    expect(logs[0].event.action).toBe('switch');
    expect(logs[0].event.service).toBe('claude');
  });

  it('should filter logs by service', () => {
    logSwitch('claude', 'openai', true);
    logSwitch('gemini', 'prod', true);

    const claudeLogs = readAuditLog({ service: 'claude' });
    expect(claudeLogs.length).toBe(1);
    expect(claudeLogs[0].event.service).toBe('claude');
  });

  it('should limit log entries', () => {
    for (let i = 0; i < 20; i++) {
      logAudit({ action: `test-${i}` });
    }

    const logs = readAuditLog({ limit: 5 });
    expect(logs.length).toBe(5);
  });
});
```

**Step 2: Run test to verify it fails**

Run: `npm test tests/unit/logger.test.js`
Expected: FAIL with "Cannot find package '../../src/utils/logger.js'"

**Step 3: Write minimal implementation**

Create `src/utils/logger.js`:

```javascript
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';

const AUDIT_LOG_PATH = path.join(os.homedir(), '.cs-cli', 'audit.log');

/**
 * è®°å½•å®¡è®¡æ—¥å¿—
 * @param {object} event - äº‹ä»¶å¯¹è±¡
 */
export function logAudit(event) {
  const entry = {
    timestamp: new Date().toISOString(),
    hostname: os.hostname(),
    username: os.userInfo().username,
    pid: process.pid,
    event
  };

  ensureAuditDir();
  const line = JSON.stringify(entry) + '\n';

  try {
    fs.appendFileSync(AUDIT_LOG_PATH, line);
  } catch (error) {
    // é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
  }
}

/**
 * è¯»å–å®¡è®¡æ—¥å¿—
 * @param {object} options - { service: string, action: string, limit: number }
 * @returns {Array<object>}
 */
export function readAuditLog(options = {}) {
  if (!fs.existsSync(AUDIT_LOG_PATH)) {
    return [];
  }

  const content = fs.readFileSync(AUDIT_LOG_PATH, 'utf-8');
  const entries = content.split('\n')
    .filter(line => line.trim())
    .map(line => {
      try {
        return JSON.parse(line);
      } catch {
        return null;
      }
    })
    .filter(Boolean);

  let filtered = entries;

  if (options.service) {
    filtered = filtered.filter(e => e.event.service === options.service);
  }

  if (options.action) {
    filtered = filtered.filter(e => e.event.action === options.action);
  }

  if (options.limit) {
    filtered = filtered.slice(-options.limit);
  }

  return filtered;
}

/**
 * æ ¼å¼åŒ–å®¡è®¡æ—¥å¿—è¾“å‡º
 * @param {Array} entries - æ—¥å¿—æ¡ç›®
 * @returns {string}
 */
export function formatAuditLog(entries) {
  return entries.map(entry => {
    const date = new Date(entry.timestamp).toLocaleString();
    const event = entry.event;
    return `[${date}] ${event.action} ${event.service || ''} ${event.variant || ''}`;
  }).join('\n');
}

/**
 * ç¡®ä¿å®¡è®¡æ—¥å¿—ç›®å½•å­˜åœ¨
 */
function ensureAuditDir() {
  const dir = path.dirname(AUDIT_LOG_PATH);
  if (!fs.existsSync(dir)) {
    try {
      fs.mkdirSync(dir, { recursive: true });
    } catch {
      // å¿½ç•¥é”™è¯¯
    }
  }
}

/**
 * è®°å½•åˆ‡æ¢æ“ä½œ
 */
export function logSwitch(service, variant, success) {
  logAudit({
    action: 'switch',
    service,
    variant,
    success,
    cwd: process.cwd()
  });
}

/**
 * è®°å½•å¤‡ä»½æ“ä½œ
 */
export function logBackup(service, timestamp) {
  logAudit({
    action: 'backup',
    service,
    timestamp
  });
}

/**
 * è®°å½•æ¢å¤æ“ä½œ
 */
export function logRestore(service, fromTimestamp) {
  logAudit({
    action: 'restore',
    service,
    from: fromTimestamp
  });
}
```

**Step 4: Run test to verify it passes**

Run: `npm test tests/unit/logger.test.js`
Expected: PASS (5 tests)

**Step 5: Create audit command**

Create `src/commands/audit.js`:

```javascript
import { readAuditLog, formatAuditLog } from '../utils/logger.js';
import chalk from 'chalk';

/**
 * æŸ¥çœ‹å®¡è®¡æ—¥å¿—
 * @param {object} options - { service: string, action: string, limit: string }
 */
export function auditLogCommand(options = {}) {
  const { service, action, limit } = options;

  const entries = readAuditLog({
    service,
    action,
    limit: parseInt(limit) || 10
  });

  if (entries.length === 0) {
    console.log(chalk.yellow('No audit log entries found'));
    return;
  }

  console.log(chalk.cyan('\nğŸ“‹ Audit Log:\n'));
  console.log(formatAuditLog(entries));
  console.log();
}
```

**Step 6: Commit**

```bash
git add src/utils/logger.js src/commands/audit.js tests/unit/logger.test.js
git commit -m "feat: add audit logging"
```

---

### Task 3.2: Create shell completion module

**Files:**
- Create: `src/core/completion.js`
- Create: `src/commands/completion.js`
- Test: `tests/unit/completion.test.js`

**Step 1: Write the failing test**

Create `tests/unit/completion.test.js`:

```javascript
import { describe, it, expect } from 'vitest';
import {
  generateCompletionScript,
  getCompletions
} from '../../src/core/completion.js';

describe('shell completion', () => {
  it('should generate bash completion script', () => {
    const script = generateCompletionScript('bash');

    expect(script).toContain('complete');
    expect(script).toContain('_cs_cli_completion');
  });

  it('should generate zsh completion script', () => {
    const script = generateCompletionScript('zsh');

    expect(script).toContain('#compdef');
    expect(script).toContain('cs-cli');
  });

  it('should complete main commands', () => {
    const completions = getCompletions('', ['cs-cli']);

    expect(completions).toContain('list');
    expect(completions).toContain('switch');
    expect(completions).toContain('init');
    expect(completions).toContain('undo');
  });

  it('should complete service names after --service', () => {
    const completions = getCompletions('', ['cs-cli', 'switch', '--service']);

    expect(completions).toContain('claude');
    expect(completions).toContain('gemini');
    expect(completions).toContain('codex');
  });
});
```

**Step 2: Run test to verify it fails**

Run: `npm test tests/unit/completion.test.js`
Expected: FAIL with "Cannot find package '../../src/core/completion.js'"

**Step 3: Write minimal implementation**

Create `src/core/completion.js`:

```javascript
import { listServices } from './registry.js';

/**
 * ç”Ÿæˆ Shell è¡¥å…¨è„šæœ¬
 * @param {string} shell - Shell ç±»å‹ (bash/zsh/powershell/fish)
 * @returns {string}
 */
export function generateCompletionScript(shell) {
  const scripts = {
    bash: bashScript(),
    zsh: zshScript(),
    powershell: powershellScript(),
    fish: fishScript()
  };

  return scripts[shell] || scripts.bash;
}

/**
 * è¡¥å…¨æŸ¥è¯¢å‡½æ•°ï¼ˆè¢«è¡¥å…¨è„šæœ¬è°ƒç”¨ï¼‰
 * @param {string} current - å½“å‰è¾“å…¥çš„è¯
 * @param {string} words - æ‰€æœ‰è¾“å…¥çš„è¯ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰
 * @returns {Array<string>}
 */
export function getCompletions(current, words) {
  const wordList = words.split(' ').filter(Boolean);
  const cmd = wordList[wordList.length - 2] || '';

  // è¡¥å…¨ä¸»å‘½ä»¤
  if (wordList.length <= 2) {
    return ['list', 'switch', 'current', 'diff', 'backup', 'restore', 'init', 'undo', 'completion', 'audit', '--help', '-h'];
  }

  // è¡¥å…¨ --service/-s å‚æ•°çš„å€¼
  if (cmd === '--service' || cmd === '-s') {
    return listServices().map(s => s.id);
  }

  // è¡¥å…¨ switch å‘½ä»¤çš„å˜ä½“å
  if (wordList[1] === 'switch' || wordList[1] === 'sw') {
    const serviceIndex = wordList.indexOf('--service') + 1 || wordList.indexOf('-s') + 1;
    const service = serviceIndex > 0 && serviceIndex < wordList.length ? wordList[serviceIndex] : 'claude';

    const adapter = getAdapter(service);
    if (adapter) {
      try {
        return adapter.scanVariants().map(v => v.name);
      } catch {
        return [];
      }
    }
  }

  // è¡¥å…¨ diff å‘½ä»¤çš„å˜ä½“å
  if (wordList[1] === 'diff') {
    const serviceIndex = wordList.indexOf('--service') + 1 || wordList.indexOf('-s') + 1;
    const service = serviceIndex > 0 && serviceIndex < wordList.length ? wordList[serviceIndex] : 'claude';

    const adapter = getAdapter(service);
    if (adapter) {
      try {
        return adapter.scanVariants().map(v => v.name);
      } catch {
        return [];
      }
    }
  }

  return [];
}

function getAdapter(service) {
  try {
    const { getAdapter } = require('./registry.js');
    return getAdapter(service);
  } catch {
    return null;
  }
}

function bashScript() {
  return `#!/bin/bash
_cs_cli_completion() {
  local cur words
  cur="\${COMP_WORDS[COMP_CWORD]}"
  words=("\${COMP_WORDS[@]}")

  COMPREPLY=($(compgen -W "$(cs-cli completion --query "\$cur" "\${words[*]}")" -- "\$cur"))
}

complete -F _cs_cli_completion cs-cli
`;
}

function zshScript() {
  return `#compdef cs-cli
_cs_cli() {
  local -a completions
  completions=("\$(cs-cli completion --query "\${words[CURRENT-1]}" "\${words[*]}")")
  _describe 'values' completions
}
`;
}

function powershellScript() {
  return `Register-ArgumentCompleter -Native -CommandName cs-cli -ScriptBlock {
  param(\$wordToComplete, \$commandAst, \$cursorPosition)
  \$completions = & cs-cli completion --query \$wordToComplete \$commandAst.ToString()
  \$completions | ForEach-Object {
    [System.Management.Automation.CompletionResult]::new(\$_, \$_, 'ParameterValue', \$_)
  }
}
`;
}

function fishScript() {
  return `complete -c cs-cli -f
complete -c cs-cli -n '__fish_use_subcommand' -a list switch current diff backup restore init undo completion audit
complete -c cs-cli -n '__fish_seen_subcommand_from switch' -a '(cs-cli completion --query (commandline -cp))'
`;
}
```

**Step 4: Create completion command**

Create `src/commands/completion.js`:

```javascript
import { generateCompletionScript } from '../core/completion.js';
import { getCompletions } from '../core/completion.js';
import chalk from 'chalk';
import fs from 'node:fs';
import path from 'node:path';

/**
 * ç”Ÿæˆæˆ–å®‰è£… Shell è¡¥å…¨è„šæœ¬
 * @param {string} shell - Shell ç±»å‹
 * @param {object} options - { install: boolean, output: string }
 */
export function completionCommand(shell, options = {}) {
  // å¤„ç†å†…éƒ¨æŸ¥è¯¢ï¼ˆç”±è¡¥å…¨è„šæœ¬è°ƒç”¨ï¼‰
  if (shell === '--query') {
    const words = options.words || '';
    const current = options.current || '';
    const completions = getCompletions(current, words);
    console.log(completions.join(' '));
    return { success: true };
  }

  // ç¡®å®šé»˜è®¤ shell
  if (!shell) {
    shell = detectShell();
  }

  // ç”Ÿæˆæˆ–å®‰è£…è¡¥å…¨è„šæœ¬
  if (options.install) {
    return installCompletion(shell, options.output);
  }

  const script = generateCompletionScript(shell);
  console.log(script);
  console.log(chalk.gray(`\n# Add to your shell config, or run: cs-cli completion ${shell} --install`));

  return { success: true };
}

/**
 * æ£€æµ‹å½“å‰ Shell
 */
function detectShell() {
  const shell = process.env.SHELL || '';
  if (shell.includes('zsh')) return 'zsh';
  if (shell.includes('bash')) return 'bash';
  if (process.platform === 'win32') return 'powershell';
  return 'bash';
}

/**
 * å®‰è£…è¡¥å…¨è„šæœ¬
 */
function installCompletion(shell, outputPath) {
  const script = generateCompletionScript(shell);

  // é»˜è®¤è¾“å‡ºè·¯å¾„
  let targetPath = outputPath;
  if (!targetPath) {
    const homeDir = require('os').homedir();
    const paths = {
      bash: path.join(homeDir, '.cs-cli', 'completion.bash'),
      zsh: path.join(homeDir, '.cs-cli', 'completion.zsh'),
      powershell: path.join(homeDir, '.cs-cli', 'completion.ps1'),
      fish: path.join(homeDir, '.config', 'fish', 'completions', 'cs-cli.fish')
    };
    targetPath = paths[shell] || paths.bash;
  }

  // ç¡®ä¿ç›®å½•å­˜åœ¨
  const dir = path.dirname(targetPath);
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true });
  }

  // å†™å…¥è„šæœ¬
  fs.writeFileSync(targetPath, script);

  const instructions = {
    bash: `Add to ~/.bashrc: source ${targetPath}`,
    zsh: `Add to ~/.zshrc: source ${targetPath}`,
    powershell: `Add to \$PROFILE: . ${targetPath}`,
    fish: `File already in correct location`
  };

  console.log(chalk.green(`âœ“ Completion script installed to: ${targetPath}`));
  console.log(chalk.yellow(instructions[shell]));

  return { success: true, path: targetPath, instructions: instructions[shell] };
}
```

**Step 5: Run test to verify it passes**

Run: `npm test tests/unit/completion.test.js`
Expected: PASS (4 tests)

**Step 6: Commit**

```bash
git add src/core/completion.js src/commands/completion.js tests/unit/completion.test.js
git commit -m "feat: add shell completion"
```

---

### Task 3.3: Update CLI entry point with new commands

**Files:**
- Modify: `bin/cs-cli.js`

**Step 1: Update bin/cs-cli.js**

Replace `bin/cs-cli.js` content with:

```javascript
#!/usr/bin/env node
import { Command } from 'commander';
import { listCommand } from '../src/commands/list.js';
import { switchCommand } from '../src/commands/switch.js';
import { currentCommand } from '../src/commands/current.js';
import { diffCommand } from '../src/commands/diff.js';
import { backupCommand } from '../src/commands/backup.js';
import { restoreCommand } from '../src/commands/restore.js';
import { initCommand } from '../src/commands/init.js';
import { undoCommand } from '../src/commands/undo.js';
import { completionCommand } from '../src/commands/completion.js';
import { auditLogCommand } from '../src/commands/audit.js';
import { defaultCommand } from '../src/commands/default.js';

const program = new Command();

program
  .name('cs-cli')
  .description('å¤šç¼–ç å·¥å…· CLI é…ç½®åˆ‡æ¢å·¥å…·')
  .version('0.2.0');

// ä¸»å‘½ä»¤
program
  .command('list')
  .alias('ls')
  .description('åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é…ç½®')
  .option('-s, --service <service>', 'ç¼–ç å·¥å…· (claude/gemini/codex)')
  .option('-a, --all', 'æ˜¾ç¤ºæ‰€æœ‰ç¼–ç å·¥å…·çš„è¯¦ç»†é…ç½®')
  .action(listCommand);

program
  .command('switch')
  .alias('sw')
  .description('åˆ‡æ¢é…ç½®')
  .argument('[variant]', 'é…ç½®å˜ä½“åç§°')
  .option('-s, --service <service>', 'ç¼–ç å·¥å…·', 'claude')
  .option('-n, --no-backup', 'ä¸åˆ›å»ºå¤‡ä»½')
  .option('-d, --dry-run', 'é¢„è§ˆåˆ‡æ¢ï¼Œä¸å®é™…æ‰§è¡Œ')
  .option('-p, --preview', 'æ˜¾ç¤ºå˜æ›´é¢„è§ˆ')
  .action(switchCommand);

program
  .command('current')
  .description('æŸ¥çœ‹å½“å‰ç”Ÿæ•ˆçš„é…ç½®')
  .option('-s, --service <service>', 'ç¼–ç å·¥å…·')
  .option('-a, --all', 'æ˜¾ç¤ºæ‰€æœ‰ç¼–ç å·¥å…·çš„è¯¦ç»†é…ç½®')
  .action(currentCommand);

program
  .command('diff')
  .description('æ¯”è¾ƒé…ç½®å·®å¼‚')
  .argument('[variant1]', 'ç¬¬ä¸€ä¸ªé…ç½®å˜ä½“')
  .argument('[variant2]', 'ç¬¬äºŒä¸ªé…ç½®å˜ä½“ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºå½“å‰é…ç½®ï¼‰')
  .option('-s, --service <service>', 'ç¼–ç å·¥å…·', 'claude')
  .action(diffCommand);

program
  .command('backup')
  .description('åˆ›å»ºé…ç½®å¤‡ä»½')
  .option('-s, --service <service>', 'ç¼–ç å·¥å…·', 'claude')
  .option('-l, --list', 'åˆ—å‡ºæ‰€æœ‰å¤‡ä»½')
  .action(backupCommand);

program
  .command('restore')
  .description('æ¢å¤é…ç½®å¤‡ä»½')
  .argument('[timestamp]', 'å¤‡ä»½æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼Œäº¤äº’å¼é€‰æ‹©ï¼‰')
  .option('-s, --service <service>', 'ç¼–ç å·¥å…·', 'claude')
  .action(restoreCommand);

// æ–°å¢å‘½ä»¤
program
  .command('init')
  .description('åˆå§‹åŒ–é…ç½®')
  .argument('[service]', 'ç¼–ç å·¥å…·', 'claude')
  .action(initCommand);

program
  .command('undo')
  .description('æ’¤é”€æœ€åä¸€æ¬¡åˆ‡æ¢')
  .option('-s, --service <service>', 'ç¼–ç å·¥å…·', 'claude')
  .action(undoCommand);

program
  .command('completion')
  .description('ç”Ÿæˆ Shell è‡ªåŠ¨è¡¥å…¨è„šæœ¬')
  .argument('[shell]', 'Shell ç±»å‹ (bash/zsh/powershell/fish)')
  .option('-i, --install', 'å®‰è£…åˆ°ç³»ç»Ÿ')
  .option('-o, --output <path>', 'è¾“å‡ºæ–‡ä»¶è·¯å¾„')
  .action(completionCommand);

program
  .command('audit')
  .description('æŸ¥çœ‹å®¡è®¡æ—¥å¿—')
  .option('-s, --service <service>', 'è¿‡æ»¤æœåŠ¡')
  .option('-a, --action <action>', 'è¿‡æ»¤æ“ä½œç±»å‹')
  .option('-n, --limit <number>', 'æ˜¾ç¤ºæ¡æ•°', '10')
  .action(auditLogCommand);

// é»˜è®¤äº¤äº’æ¨¡å¼
program.action(defaultCommand);

program.parse();
```

**Step 2: Commit**

```bash
git add bin/cs-cli.js
git commit -m "feat: update CLI with new commands (init, undo, completion, audit)"
```

---

### Task 3.4: Update switch command to integrate logging

**Files:**
- Modify: `src/commands/switch.js`

**Step 1: Update switch.js to add logging**

Add to `src/commands/switch.js`:

```javascript
import { logSwitch } from '../utils/logger.js';

// åœ¨ switchCommand å‡½æ•°ä¸­ï¼Œè°ƒç”¨ switchConfig åæ·»åŠ ï¼š
logSwitch(service, variant, result.success);
```

**Step 2: Update backup command to add logging**

Add to `src/commands/backup.js`:

```javascript
import { logBackup } from '../utils/logger.js';

// åœ¨åˆ›å»ºå¤‡ä»½åæ·»åŠ ï¼š
if (result.success) {
  logBackup(service, result.timestamp);
}
```

**Step 3: Commit**

```bash
git add src/commands/switch.js src/commands/backup.js
git commit -m "feat: integrate audit logging in commands"
```

---

### Task 3.5: Update README with new features

**Files:**
- Modify: `README.md`

**Step 1: Update README.md**

Add sections for new commands:

```markdown
## æ–°å¢å‘½ä»¤

### init - åˆå§‹åŒ–é…ç½®

\`\`\`bash
cs-cli init claude
\`\`\`

äº¤äº’å¼åˆå§‹åŒ–å‘å¯¼ï¼Œå¸®åŠ©åˆ›å»ºé…ç½®ç›®å½•å’Œç¤ºä¾‹æ–‡ä»¶ã€‚

### undo - æ’¤é”€åˆ‡æ¢

\`\`\`bash
cs-cli undo
cs-cli undo -s gemini
\`\`\`

æ’¤é”€æœ€åä¸€æ¬¡åˆ‡æ¢æ“ä½œï¼Œæ¢å¤åˆ°ä¸Šä¸€ä¸ªé…ç½®ã€‚

### completion - Shell è¡¥å…¨

\`\`\`bash
# ç”Ÿæˆè¡¥å…¨è„šæœ¬
cs-cli completion bash

# å®‰è£…è¡¥å…¨è„šæœ¬
cs-cli completion bash --install
\`\`\`

### audit - å®¡è®¡æ—¥å¿—

\`\`\`bash
# æŸ¥çœ‹æœ€è¿‘ 10 æ¡æ“ä½œ
cs-cli audit

# è¿‡æ»¤ç‰¹å®šæœåŠ¡
cs-cli audit -s claude

# æŸ¥çœ‹æ›´å¤šæ¡ç›®
cs-cli audit -n 50
\`\`\`
```

**Step 2: Commit**

```bash
git add README.md
git commit -m "docs: update README with new commands"
```

---

## Phase 4: æœ€ç»ˆæµ‹è¯•å’Œæ¸…ç†

### Task 4.1: Run all tests

**Step 1: Run full test suite**

Run: `npm test`

Expected: All new tests pass (30+ tests total)

**Step 2: Fix any failing tests**

If any tests fail, fix issues and commit.

**Step 3: Commit final test updates**

```bash
git add tests/
git commit -m "test: fix failing tests and finalize test suite"
```

---

### Task 4.2: Integration test for concurrent operations

**Files:**
- Create: `tests/integration/concurrent.test.js`

**Step 1: Create concurrent test**

Create `tests/integration/concurrent.test.js`:

```javascript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import fs from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import { switchConfig } from '../../src/core/switcher.js';

describe('concurrent operations', () => {
  let testDir;
  let originalEnv;

  beforeEach(() => {
    testDir = fs.mkdtempSync(path.join(os.tmpdir(), 'cs-cli-concurrent-'));
    originalEnv = process.env.CLAUDE_CONFIG_DIR;
    process.env.CLAUDE_CONFIG_DIR = testDir;

    fs.mkdirSync(testDir, { recursive: true });
    fs.writeFileSync(
      path.join(testDir, 'settings.json'),
      JSON.stringify({ api_key: 'sk-default' })
    );
    fs.writeFileSync(
      path.join(testDir, 'settings.json.openai'),
      JSON.stringify({ api_key: 'sk-openai' })
    );
    fs.writeFileSync(
      path.join(testDir, 'settings.json.local'),
      JSON.stringify({ api_key: 'sk-local' })
    );
  });

  afterEach(() => {
    process.env.CLAUDE_CONFIG_DIR = originalEnv;
    if (fs.existsSync(testDir)) {
      fs.rmSync(testDir, { recursive: true, force: true });
    }
  });

  it('should handle concurrent switches safely', async () => {
    const switches = [
      switchConfig('claude', 'openai'),
      switchConfig('claude', 'local'),
      switchConfig('claude', 'openai')
    ];

    const results = await Promise.allSettled(switches);

    // æ‰€æœ‰æ“ä½œéƒ½åº”è¯¥æˆåŠŸï¼ˆè¿›ç¨‹éš”ç¦»ï¼‰
    results.forEach(result => {
      expect(result.status).toBe('fulfilled');
      if (result.status === 'fulfilled') {
        expect(result.value.success).toBe(true);
      }
    });
  });
});
```

**Step 2: Run test**

Run: `npm test tests/integration/concurrent.test.js`

**Step 3: Commit**

```bash
git add tests/integration/concurrent.test.js
git commit -m "test: add concurrent operations test"
```

---

### Task 4.3: Final cleanup and verification

**Step 1: Update package.json version**

Update version to 0.2.0:

```json
{
  "version": "0.2.0"
}
```

**Step 2: Run linter**

Run: `npm run lint`

Fix any linting issues.

**Step 3: Final commit**

```bash
git add package.json
git commit -m "chore: bump version to 0.2.0"
```

---

## å®æ–½å®Œæˆæ£€æŸ¥æ¸…å•

- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ (30+ tests)
- [ ] æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡
- [ ] ä»£ç é£æ ¼æ£€æŸ¥é€šè¿‡
- [ ] README æ›´æ–°å®Œæˆ
- [ ] ç‰ˆæœ¬å·æ›´æ–°ä¸º 0.2.0
- [ ] æ‰€æœ‰æ–°å‘½ä»¤å¯æ­£å¸¸è¿è¡Œ

---

## æ€»ç»“

æœ¬è®¡åˆ’æ¶µç›– 12 ä¸ªæ”¹è¿›é¡¹çš„å®æ–½ï¼Œåˆ†ä¸º 3 ä¸ªé˜¶æ®µï¼š

1. **åŸºç¡€è®¾æ–½** - åŸå­æ“ä½œã€è¿›ç¨‹éš”ç¦»ã€è¯­ä¹‰éªŒè¯
2. **åŠŸèƒ½å¢å¼º** - init å‘½ä»¤ã€é”™è¯¯æ ¼å¼åŒ–ã€äº¤äº’æ¢å¤ã€æ’¤é”€åŠŸèƒ½
3. **ä½“éªŒä¼˜åŒ–** - Shell è¡¥å…¨ã€å®¡è®¡æ—¥å¿—

é¢„è®¡å·¥ä½œé‡ï¼šçº¦ 40 å°æ—¶
